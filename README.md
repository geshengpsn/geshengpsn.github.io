# 项目经历

## 协作机器人交互平台
<div style="display: flex;">
<video src="b/pick.mp4" controls="controls" width="180" height="320"></video>
<video src="b/ttt.mp4" controls="controls" width="180" height="320"></video>
<video src="b/cali.mp4" controls="controls" width="180" height="320"></video>
<video src="b/grasp.mp4" controls="controls" width="180" height="320"></video>
<video src="b/sort.mp4" controls="controls" width="180" height="320"></video>
</div>


## Rust 机器人动力学运动学库
<video src="rust_ik.mov" controls="controls" width="640" height="360"></video>

## ArUco 二维码识别库
<img src="aruco/all.png">



## Mesh 几何库
![](mesh/bunny.png)

## DrakeNotebook docker 教学开发环境
![](docker.png)

## nurbs 曲线曲面库
<img src="nurbs/all.png">



## liealg

## Universl Ebodiment Interface 通用具身接口

### 背景
项目旨在为具身智能的多模态数据采集与摇操提供一个通用的工具链、可扩展的开源数据与模型。具体来说就是首先使用手持硬件夹爪进行机器人操作数据采集与机器人摇操；采集的数据再进行可视化、编辑、标注、上传；使用共建的大数据集，通过模仿学习等方法，可以训练出性能更好的具身智能模型。

### 手持夹爪硬件
使用手持夹爪硬件进行数据收集时共收集5种多模态数据，其分别为空间位姿、RGB图像、深度、夹爪开合角度、柔性手指触觉共5种模态。

#### UEI - vision based finger tactile 基于视觉的柔性手指触觉 
#### ati 硬件驱动

### 机器人摇操

#### motor
#### teleoperation
<video src="dc.mp4" controls="controls" width="640" height="360">
</video>

#### pymagiclaw 通用机器人操作控制库

### 数据可视化

## urdf-parse  URDF 机器人模型文件解析库
background
method
result
<video src="rust_ik.mov" controls="controls" width="640" height="360"></video>


## UEI - rerun (online, offline) 基于rerun的多模态数据可视化（在线与离线）
background
method
result


## UEI - pymagiclaw 通用机器人操作控制库
background
method
result